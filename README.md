# Data Science

* ### [data_analytics.pdf](https://github.com/roboticcam/machine-learning-notes/blob/master/data_analytics.pdf) ###
Three perspectives into machine learning and Data Science. Supervised vs Unsupervised Learning, Classification accuracy


* ### [regression.pdf](https://github.com/roboticcam/machine-learning-notes/blob/master/regression.pdf) ###
Classification: Logistic and Softmax; Regression: Linear, polynomial; Mix Effect model

* ### [recommendation.pdf](https://github.com/roboticcam/machine-learning-notes/blob/master/recommendation.pdf) ###
collaborative filtering, Factorization Machines, Non-Negative Matrix factorisation, Multiplicative Update Rule

* ### [ai_ml_dl.pdf](https://github.com/roboticcam/machine-learning-notes/blob/master/ai_ml_dl.pdf) ###
this is what I used to talk to industry about AI, ML and DL

* ### [dimension_reduction.pdf](https://github.com/roboticcam/machine-learning-notes/blob/master/dimension_reduction.pdf) ###
classic PCA and t-SNE


# Probability and Statistics Background

* ### [bayesian.pdf](https://github.com/roboticcam/machine-learning-notes/blob/master/bayesian.pdf) ###
revision on Bayes model include Bayesian predictive model, conditional expectation

* ### [probability.pdf](https://github.com/roboticcam/machine-learning-notes/blob/master/probability.pdf) ###
some useful distributions, conjugacy, MLE, MAP, Exponential family and natural parameters

* ### [statistics.pdf](https://github.com/roboticcam/machine-learning-notes/blob/master/statistics.pdf) ###
useful statistical properties to help us prove things, include Chebyshev and Markov inequality


# Probabilistic Model

* ### [em.pdf](https://github.com/roboticcam/machine-learning-notes/blob/master/em.pdf) ###
Proof of convergence for E-M, examples of E-M through Gaussian Mixture Model

* ### [dynamic_model.pdf](https://github.com/roboticcam/machine-learning-notes/blob/master/dynamic_model.pdf) ###
explain in detail of Kalman Filter and Hidden Markov Model


# Inference

* ### [variational.pdf](https://github.com/roboticcam/machine-learning-notes/blob/master/em.pdf) ###
explain Variational Bayes both the non-exponential and exponential family distribution plus stochastic variational inference.


* ### [stochastic_matrices.pdf](https://github.com/roboticcam/machine-learning-notes/blob/master/stochastic_matrices.pdf) ###
stochastic matrix, Power Method Convergence Theorem, detailed balance and PageRank algorithm


* ### [introduction_monte_carlo.pdf](https://github.com/roboticcam/machine-learning-notes/blob/master/introduction_monte_carlo.pdf) ###
inverse CDF, rejection, adaptive rejection, importance sampling


* ### [markov_chain_monte_carlo.pdf](https://github.com/roboticcam/machine-learning-notes/blob/master/markov_chain_monte_carlo.pdf) ###
M-H, Gibbs, Slice Sampling, Elliptical Slice sampling, Swendesen-Wang, demonstrate collapsed Gibbs using LDA

* ### [particle_filter.pdf](https://github.com/roboticcam/machine-learning-notes/blob/master/particle_filter.pdf) ###
Sequential Monte-Carlo, Condensational Filter algorithm, Auxiliary Particle Filter



