# Data Science

* ### [data_analytics.pdf](https://github.com/roboticcam/machine-learning-notes/blob/master/data_analytics.pdf) ###
Three perspectives into machine learning and Data Science. Supervised vs Unsupervised Learning, Classification accuracy


* ### [regression.pdf](https://github.com/roboticcam/machine-learning-notes/blob/master/regression.pdf) ###
Classification: Logistic and Softmax; Regression: Linear, polynomial; Mix Effect model

* ### [recommendation.pdf](https://github.com/roboticcam/machine-learning-notes/blob/master/recommendation.pdf) ###
collaborative filtering, Factorization Machines, Non-Negative Matrix factorisation, Multiplicative Update Rule

* ### [ai_ml_dl.pdf](https://github.com/roboticcam/machine-learning-notes/blob/master/ai_ml_dl.pdf) ###
this is what I used to talk to industry about AI, ML and DL

* ### [dimension_reduction.pdf](https://github.com/roboticcam/machine-learning-notes/blob/master/dimension_reduction.pdf) ###
classic PCA and t-SNE

# Probability and Statistics Background

* ### [bayesian.pdf](https://github.com/roboticcam/machine-learning-notes/blob/master/bayesian.pdf) ###
revision on Bayes model include Bayesian predictive model, conditional expectation

* ### [probability.pdf](https://github.com/roboticcam/machine-learning-notes/blob/master/probability.pdf) ###
some useful distributions, conjugacy, MLE, MAP, Exponential family and natural parameters

* ### [statistics.pdf](https://github.com/roboticcam/machine-learning-notes/blob/master/statistics.pdf) ###
useful statistical properties to help us prove things, include Chebyshev and Markov inequality


# Probabilistic Model

* ### [em.pdf](https://github.com/roboticcam/machine-learning-notes/blob/master/em.pdf) ###
Proof of convergence for E-M, examples of E-M through Gaussian Mixture Model

* ### [dynamic_model.pdf](https://github.com/roboticcam/machine-learning-notes/blob/master/dynamic_model.pdf) ###
explain in detail of Kalman Filter and Hidden Markov Model



