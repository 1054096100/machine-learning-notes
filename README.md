# Data Science

* ### [Introduction to Data Analytics](https://github.com/roboticcam/machine-learning-notes/blob/master/data_analytics.pdf) ###
Three perspectives into machine learning and Data Science. Supervised vs Unsupervised Learning, Classification accuracy


* ### [Regression methods](https://github.com/roboticcam/machine-learning-notes/blob/master/regression.pdf) ###
Classification: Logistic and Softmax; Regression: Linear, polynomial; Mix Effect model

* ### [Recommendation system](https://github.com/roboticcam/machine-learning-notes/blob/master/recommendation.pdf) ###
collaborative filtering, Factorization Machines, Non-Negative Matrix factorisation, Multiplicative Update Rule

* ### [Industry General talk](https://github.com/roboticcam/machine-learning-notes/blob/master/ai_ml_dl.pdf) ###
this is what I used to talk to industry about AI, ML and DL

* ### [Dimension Reduction](https://github.com/roboticcam/machine-learning-notes/blob/master/dimension_reduction.pdf) ###
classic PCA and t-SNE


# Probability and Statistics Background

* ### [Bayesian model](https://github.com/roboticcam/machine-learning-notes/blob/master/bayesian.pdf) ###
revision on Bayes model include Bayesian predictive model, conditional expectation

* ### [Probabilistic Estimation](https://github.com/roboticcam/machine-learning-notes/blob/master/probability.pdf) ###
some useful distributions, conjugacy, MLE, MAP, Exponential family and natural parameters

* ### [Statistics Properties](https://github.com/roboticcam/machine-learning-notes/blob/master/statistics.pdf) ###
useful statistical properties to help us prove things, include Chebyshev and Markov inequality


# Probabilistic Model

* ### [Expectation Maximisation](https://github.com/roboticcam/machine-learning-notes/blob/master/em.pdf) ###
Proof of convergence for E-M, examples of E-M through Gaussian Mixture Model

* ### [State Space Model (Dynamic model)](https://github.com/roboticcam/machine-learning-notes/blob/master/dynamic_model.pdf) ###
explain in detail of Kalman Filter and Hidden Markov Model


# Inference

* ### [Variational Inference](https://github.com/roboticcam/machine-learning-notes/blob/master/variational.pdf) ###
explain Variational Bayes both the non-exponential and exponential family distribution plus stochastic variational inference.


* ### [Stochastic Matrices](https://github.com/roboticcam/machine-learning-notes/blob/master/stochastic_matrices.pdf) ###
stochastic matrix, Power Method Convergence Theorem, detailed balance and PageRank algorithm


* ### [Introduction to Monte Carlo](https://github.com/roboticcam/machine-learning-notes/blob/master/introduction_monte_carlo.pdf) ###
inverse CDF, rejection, adaptive rejection, importance sampling


* ### [Markov Chain Monte Carlo](https://github.com/roboticcam/machine-learning-notes/blob/master/markov_chain_monte_carlo.pdf) ###
M-H, Gibbs, Slice Sampling, Elliptical Slice sampling, Swendesen-Wang, demonstrate collapsed Gibbs using LDA

* ### [Particle Filter (Sequential Monte-Carlo)](https://github.com/roboticcam/machine-learning-notes/blob/master/particle_filter.pdf) ###
Sequential Monte-Carlo, Condensational Filter algorithm, Auxiliary Particle Filter



